# Local LLM - Sources

**Topic:** Local LLM, Self-Hosted Models, Ollama  
**Last Updated:** 2026-02-25  
**Next Update:** 2026-03-03  
**Total Sources:** 10

## Subreddits (Primary)

### r/LocalLLaMA
- **URL:** https://www.reddit.com/r/LocalLLaMA/
- **RSS:** https://www.reddit.com/r/LocalLLaMA/.rss
- **Focus:** Self-hosted LLMs, local deployment, privacy
- **Why valuable:** Most active community, model releases, tips

### r/ollama
- **URL:** https://www.reddit.com/r/ollama/
- **RSS:** https://www.reddit.com/r/ollama/.rss
- **Focus:** Ollama-specific discussion, troubleshooting
- **Why valuable:** Tool-specific community, real usage

## YouTube Channels

### Tech With Tim
- **URL:** https://www.youtube.com/@TechWithTim
- **RSS:** https://www.youtube.com/feeds/videos.xml?channel_id=UC4JX40jDee_tINbkjycV4Sg
- **Recent:** "Learn Ollama in 15 Minutes"
- **Focus:** Ollama tutorials, local LLM setup
- **Why valuable:** Clear tutorials, beginner-friendly

### Network Chuck (Local AI)
- **URL:** https://www.youtube.com/@NetworkChuck
- **RSS:** https://www.youtube.com/feeds/videos.xml?channel_id=UC9x0AN7BWHpCDHSm9NiJFJQ
- **Focus:** Self-hosting, network setup
- **Why valuable:** Infrastructure perspective

## Blogs

### Tailscale Blog (AI Self-Hosting)
- **URL:** https://tailscale.com/blog/
- **RSS:** https://tailscale.com/blog/rss.xml
- **Focus:** Secure self-hosting, remote access
- **Why valuable:** Production deployment patterns

### Pinggy Blog
- **URL:** https://pinggy.io/blog/
- **RSS:** https://pinggy.io/blog/rss.xml
- **Focus:** Self-hosting guides, LLM deployment
- **Why valuable:** Step-by-step tutorials

### n8n Blog (Local LLM)
- **URL:** https://blog.n8n.io/
- **RSS:** https://blog.n8n.io/feed (filter "ollama" or "local")
- **Focus:** Workflow automation with local models
- **Why valuable:** Integration patterns

### BentoML Blog
- **URL:** https://www.bentoml.com/blog
- **RSS:** https://www.bentoml.com/blog/rss.xml
- **Focus:** Open-source LLM deployment
- **Why valuable:** Production-grade deployment

## Official

### Ollama GitHub
- **URL:** https://github.com/ollama/ollama
- **RSS:** https://github.com/ollama/ollama/releases.atom
- **Focus:** Official releases, model updates
- **Why valuable:** Primary tool for local LLMs

### llama.cpp
- **URL:** https://github.com/ggerganov/llama.cpp
- **RSS:** https://github.com/ggerganov/llama.cpp/releases.atom
- **Focus:** CPU inference, quantization
- **Why valuable:** Core inference engine

---

## Discovery Log

**2026-02-25:** Initial meta-discovery - 10 sources
- Subreddits: 2 (r/LocalLLaMA, r/ollama) - PRIMARY SOURCES
- YouTube: 2 (Tech With Tim, Network Chuck)
- Blogs: 4 (Tailscale, Pinggy, n8n, BentoML)
- Official: 2 (Ollama, llama.cpp)

**Quality Tier:**
- **Tier 1:** r/LocalLLaMA, Ollama GitHub, Tech With Tim
- **Tier 2:** r/ollama, llama.cpp, Tailscale, BentoML
- **Tier 3:** Others

**Note:** Reddit is PRIMARY source for this topic - most active community discussions happen there
